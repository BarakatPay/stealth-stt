import asyncio
import tempfile
import streamlit as st
import torch
from pydub import AudioSegment
import edge_tts
import nest_asyncio
from dotenv import load_dotenv
from huggingface_hub import login
from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC
from groq import Groq
import numpy as np
import time

# ğŸ›  Load .env
load_dotenv()

# ğŸ§  Config
HF_MODEL_ID = st.secrets["HF_MODEL_ID"]
TTS_VOICE = st.secrets["TTS_VOICE"]
TARGET_SR = int(st.secrets["TARGET_SR"])
HF_TOKEN = st.secrets["HF_API_TOKEN"]
GROQ_API_KEY = st.secrets["GROQ_API_KEY"]

if not HF_TOKEN or not GROQ_API_KEY:
    st.error("âŒ Missing HF_TOKEN or GROQ_API_KEY in your .env file.")
    st.stop()

# ğŸ” Hugging Face login
login(token=HF_TOKEN)

# ğŸ§  Groq client
groq_client = Groq(api_key=GROQ_API_KEY)

# ğŸ“„ Streamlit UI
nest_asyncio.apply()
st.set_page_config(page_title="Pashto STT â†’ Groq â†’ Pashto TTS", page_icon="ğŸ™", layout="centered")
st.title("ğŸ™ Pashto STT â†’ LLM â†’ Pashto TTS")

st.subheader("ğŸ¤ Record Pashto Audio")
audio_value = st.audio_input("ğŸ™ Record a voice message")
uploaded_file = False


@st.cache_resource
def load_model():
    processor = Wav2Vec2Processor.from_pretrained(HF_MODEL_ID)
    model = Wav2Vec2ForCTC.from_pretrained(HF_MODEL_ID)
    model.eval()
    return processor, model


processor, model = load_model()


async def generate_pashto_tts(text: str, output_path: str):
    communicator = edge_tts.Communicate(text, voice=TTS_VOICE)
    await communicator.save(output_path)


def generate_tts_blocking(text: str, path: str):
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    loop.run_until_complete(generate_pashto_tts(text, path))


def convert_to_wav(uploaded_bytes: bytes, ext: str) -> str:
    with tempfile.NamedTemporaryFile(delete=False, suffix=f".{ext}") as temp_in:
        temp_in.write(uploaded_bytes)
        input_path = temp_in.name
    output_path = input_path.replace(f".{ext}", ".wav")
    audio = AudioSegment.from_file(input_path, format=ext)
    audio = audio.set_channels(1).set_frame_rate(TARGET_SR)
    audio.export(output_path, format="wav")
    return output_path


def load_audio(path: str, target_sr: int = 16000) -> torch.Tensor:
    audio = AudioSegment.from_file(path)
    audio = audio.set_channels(1).set_frame_rate(target_sr)
    samples = np.array(audio.get_array_of_samples()).astype(np.float32) / 32768.0  # normalize
    return torch.from_numpy(samples)


if audio_value or uploaded_file:
    if audio_value:
        audio_bytes = audio_value.getvalue()
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
            f.write(audio_bytes)
            temp_wav_path = f.name
    elif uploaded_file:
        ext = uploaded_file.name.split(".")[-1].lower()
        audio_bytes = uploaded_file.read()
        if ext != "wav":
            temp_wav_path = convert_to_wav(audio_bytes, ext)
        else:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
                f.write(audio_bytes)
                temp_wav_path = f.name

    # st.audio(audio_bytes, format="audio/wav")

    try:
        waveform = load_audio(temp_wav_path)
    except Exception as e:
        st.error(f"âŒ Failed to load audio: {e}")
        st.stop()

    # st.subheader("ğŸ“ˆ Audio Waveform")
    # downsampled = waveform.numpy()[::10]
    # st.line_chart(downsampled)
    # st.markdown(f"â± **Duration**: {waveform.shape[-1] / TARGET_SR:.2f} sec")

    inputs = processor(waveform, sampling_rate=TARGET_SR, return_tensors="pt", padding=True)
    with torch.no_grad():
        logits = model(**inputs).logits
    predicted_ids = torch.argmax(logits, dim=-1)
    transcription = processor.batch_decode(predicted_ids)[0]

    st.subheader("ğŸ“ Transcription")
    st.success(transcription)

    prompt = f"""
              Ø³ØªØ§ Ø¯Ù†Ø¯Ù‡ Ø¯Ø§ Ø¯Ù‡ Ú†Û Ú©Ø§Ø±ÙˆÙˆÙ†Ú©Ùˆ ØªÙ‡ Ù¾Ù‡ Ù¾ÚšØªÙˆ Ú˜Ø¨Ù‡ Ù„Ù†Ú‰ØŒ Ø¯Ù‚ÛŒÙ‚ Ø§Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ ÚÙˆØ§Ø¨ÙˆÙ†Ù‡ ÙˆØ±Ú©Ú“ÛØŒ Ù„Ú©Ù‡ ÛŒÙˆ ÚšÙ‡ Ù…Ù„Ú«Ø±ÛŒ.
              [Your task is to provide concise, accurate, and friendly answers to users in Pashto, like a good friend.]
    
              Ø¨ÛÙ„Ú«Û:
              [Examples:]
    
              User says (in Pashto): Ø³Ù„Ø§Ù…ØŒ ØªÙ‡ Ú…Ù†Ú«Ù‡ ÙŠÛØŸ
              Model reply (in Pashto): Ø²Ù‡ ÚšÙ‡ ÙŠÙ…ØŒ Ù…Ù†Ù†Ù‡. ØªÙ‡ Ú…Ù†Ú«Ù‡ ÙŠÛØŸ
              [User: Hello, how are you? -> Model: I am fine, thank you. How are you?]
    
              User says (in Pashto): Ø¯ Ú©Ø§Ø¨Ù„ Ù‡ÙˆØ§ Ú…Ù†Ú«Ù‡ Ø¯Ù‡ØŸ
              Model reply (in Pashto): Ù†Ù† Ù¾Ù‡ Ú©Ø§Ø¨Ù„ Ú©Û Ù‡ÙˆØ§ ÙˆØ±ÛŒÚ Ø¯Ù‡. ÚšÙ‡ Ø¨Ù‡ ÙˆÙŠ Ú©Ù‡ Ú†ØªØ±Û Ø¯Ø±Ø³Ø±Ù‡ ÙˆÙŠ!
              [User: How is the weather in Kabul? -> Model: The weather in Kabul today is cloudy. It would be good to have an umbrella with you!]
    
              User says (in Pashto): Ø¯ Ù¾ÚšØªÙ†Ùˆ ØªØ§Ø±ÛŒØ® Ú…Ù‡ Ø¯ÛŒØŸ
              Model reply (in Pashto): Ù¾ÚšØªØ§Ù†Ù‡ ÛŒÙˆÙ‡ Ù„Ø±ØºÙˆÙ†Û Ù‚ÙˆÙ… Ø¯Ù‡ Ú†Û Ø¨Ú‰Ø§ÛŒÙ‡ Ú©Ù„ØªÙˆØ± Ø§Ùˆ ØªØ§Ø±ÛŒØ® Ù„Ø±ÙŠ. Ú‰ÛØ± Ù¾Ù‡ Ø²Ú“Ù‡ Ù¾ÙˆØ±Û!
              [User: What is the history of Pashtuns? -> Model: Pashtuns are an ancient people with a rich culture and history. Very interesting!]
    
              User says (in Pashto): ØªØ± Ù¼ÙˆÙ„Ùˆ Ù„ÙˆÚ“ ØºØ± Ú©ÙˆÙ… Ø¯ÛŒØŸ
              Model reply (in Pashto): Ø§ÛŒÙˆØ±ÛŒØ³Ù¼! Ø§ÛŒØ§ ØªÙ‡ ØºÙˆØ§Ú“Û Ú†Û Ù†ÙˆØ± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù‡Ù… Ø¯Ø±Ú©Ú“Ù…ØŸ
              [User: What is the highest mountain? -> Model: Everest! Would you like me to give you more information?]
    
              User says (in Pashto): Ø§ÙØºØ§Ù†Ø³ØªØ§Ù† Ø¯ Ú©ÙˆÙ…Û Ù‚Ø§Ø±Û Ø¨Ø±Ø®Ù‡ Ø¯ÛŒØŸ
              Model reply (in Pashto): Ø§Ø³ÛŒØ§. Ø¢ÛŒØ§ Ù†ÙˆØ± Ú…Ù‡ Ù‡Ù… ØºÙˆØ§Ú“Û Ú†Û Ù¾ÙˆÙ‡ Ø´ÛØŸ
              [User: Which continent is Afghanistan part of? -> Model: Asia. Is there anything else you'd like to know?]
    
              User says (in Pashto): Ø¯ Ù…ÙˆÙ¼Ø± Ú†Ù„ÙˆÙˆÙ„Ùˆ Ù„Ù¾Ø§Ø±Ù‡ Ú…Ù‡ ØªÙ‡ Ø§Ú“ØªÛŒØ§ Ù„Ø±ÙˆØŸ
              Model reply (in Pashto): Ù…ÙˆÙ¼Ø± Ú†Ù„ÙˆÙˆÙ†Ú©ÛŒ Ø¬ÙˆØ§Ø² ØªÙ‡ Ø§Ú“ØªÛŒØ§ Ù„Ø±Û. ØªÙ‡ ØºÙˆØ§Ú“Û Ù…ÙˆÙ¼Ø± ÙˆÚ†Ù„ÙˆÛØŸ
              [User: What do we need to drive a car? -> Model: You need a driving license. Do you want to drive a car?]
    
              User says (in Pashto): Ø§ÙˆØ¨Ù‡ Ù„Ù‡ Ú©ÙˆÙ…Ùˆ Ø¹Ù†Ø§ØµØ±Ùˆ Ø¬ÙˆÚ“Û Ø¯ÙŠØŸ
              Model reply (in Pashto): Ø§ÙˆØ¨Ù‡ Ù„Ù‡ Ù‡Ø§ÛŒØ¯Ø±ÙˆØ¬Ù† Ø§Ùˆ Ø§Ú©Ø³ÛŒØ¬Ù† Ú…Ø®Ù‡ Ø¬ÙˆÚ“Û Ø¯ÙŠ. Ø­ÛŒØ±Ø§Ù†ÙˆÙˆÙ†Ú©Û Ù†Ù‡ Ø¯Ù‡ØŸ
              [User: What elements are water made of? -> Model: Water is made of Hydrogen and Oxygen. Isn't that amazing?]
    
              User says (in Pashto): {transcription}.
              Model reply (in Pashto):
            """

    try:
        with st.spinner("ğŸ¤– Thinking..."):
            groq_response = groq_client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "You are a helpful Pashto-speaking assistant."},
                    {"role": "user", "content": prompt}
                ],
                model="llama-3.3-70b-versatile"
            )
        pashto_reply = groq_response.choices[0].message.content.strip()
    except Exception as e:
        pashto_reply = f"âŒ Error: {e}"

    st.subheader("ğŸ¤– LLM says")
    st.info(pashto_reply)

    st.subheader("ğŸ”Š Pashto TTS")
    tts_out = "groq_pashto.mp3"
    try:
        generate_tts_blocking(pashto_reply, tts_out)
        with open(tts_out, "rb") as f:
            tts_bytes = f.read()
        st.audio(tts_bytes, format="audio/mp3")
        # st.download_button("â¬‡ Download Audio", tts_bytes, file_name="groq_pashto.mp3")
    except Exception as e:
        st.error(f"TTS Generation Failed: {e}")
    finally:
        time.sleep(5)
        st.empty()
else:
    st.warning("ğŸ“¢ Speak to begin.")
    st.empty()
